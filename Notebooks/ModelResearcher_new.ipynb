{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0eb9ab2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.models\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "import zipfile\n",
    "import sys\n",
    "import requests, io\n",
    "import re \n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2156f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text:str, stop_words, punctuation_marks, morph):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    preprocessed_text = []\n",
    "    for token in tokens:\n",
    "        if token not in punctuation_marks:\n",
    "            lemma = morph.parse(token)[0].normal_form\n",
    "            if re.match(r'(\\d.|\\d)', lemma) is None:\n",
    "                if lemma not in stop_words:\n",
    "                    preprocessed_text.append(lemma)\n",
    "    return preprocessed_text\n",
    "\n",
    "def read_json(path: str):\n",
    "    file = open(path)\n",
    "    data = json.load(file)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def calc_f1_score(sim, df, match_threshold):\n",
    "    (TP, FP, FN, TN) = (0, 0, 0, 0)\n",
    "    for i in range(sim.size):\n",
    "        if df['need_match'][i]:\n",
    "            if sim[i] >= match_threshold: \n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if sim[i] >= match_threshold: \n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "\n",
    "    return round(float(2*TP / (2*TP + FP + FN)), 3)\n",
    "\n",
    "punctuation_marks = ['!', ',', '(', ')', ';', ':', '-', '?', '.', '..', '...', \"\\\"\", \"/\", \"\\`\\`\", \"»\", \"«\" ]\n",
    "stop_words = stopwords.words(\"russian\")\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5600de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelResearcher:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "    def preprocess_and_save(self, data_df: pd.DataFrame, path, text_field='text') -> pd.DataFrame:\n",
    "        # for preprocessing dataset. Use it only in critical cases cause it's too slow on big datasets\n",
    "        data_df['preprocessed_' + text_field] = data_df.apply(lambda row: preprocess(row[text_field], punctuation_marks, stop_words, morph), axis=1)\n",
    "        data_df_preprocessed = data_df.copy()\n",
    "        data_df_preprocessed = data_df_preprocessed.drop(columns=[text_field], axis=1)\n",
    "        data_df_preprocessed.reset_index(drop=True, inplace=True)\n",
    "        if path is not None:\n",
    "            data_df_preprocessed.to_json(path)\n",
    "        return data_df_preprocessed\n",
    "    \n",
    "    def preprocess_and_save_pairs(self, data_df: pd.DataFrame, path, text_field_1, text_field_2) -> pd.DataFrame:\n",
    "        data_df['preprocessed_' + text_field_1] = data_df.apply(lambda row: preprocess(row[text_field_1], punctuation_marks, stop_words, morph), axis=1)\n",
    "        data_df['preprocessed_' + text_field_2] = data_df.apply(lambda row: preprocess(row[text_field_2], punctuation_marks, stop_words, morph), axis=1)\n",
    "        data_df_preprocessed = data_df.copy()\n",
    "        data_df_preprocessed = data_df_preprocessed.drop(columns=[text_field_1, text_field_2], axis=1)\n",
    "        data_df_preprocessed.reset_index(drop=True, inplace=True)\n",
    "        if path is not None:\n",
    "            data_df_preprocessed.to_json(path)\n",
    "        return data_df_preprocessed\n",
    "    \n",
    "    def train(self, data_df: pd.DataFrame, model=\"w2v\"):            \n",
    "        if model == \"w2v\":\n",
    "            train_part = data_df['preprocessed_texts']\n",
    "            self.model = gensim.models.Word2Vec(sentences=train_part, min_count=5, vector_size=50, epochs=5)\n",
    "        elif model == \"fast_text\":\n",
    "            print(\"fast_text\")\n",
    "            train_part = data_df['preprocessed_texts'].tolist()\n",
    "            self.model = gensim.models.FastText(vector_size=50, min_count=5)\n",
    "            self.model.build_vocab(corpus_iterable=train_part)\n",
    "            self.model.train(corpus_iterable=train_part, total_examples=len(train_part), epochs=5)\n",
    "        return\n",
    "    \n",
    "    def predict_sentences_similarity(self, sentences_1: pd.Series, sentences_2: pd.Series):\n",
    "        if sentences_1.size != sentences_2.size:\n",
    "            return None\n",
    "        else:\n",
    "            if self.model is not None:\n",
    "                sentences_sim = np.zeros(sentences_1.size)\n",
    "                sz = sentences_1.size\n",
    "#                 print(f'index_to_key: {self.model.wv.index_to_key}')\n",
    "                for i in range(sz): \n",
    "                    sentences_1_words = [w for w in sentences_1[i] if w in self.model.wv.index_to_key]\n",
    "                    sentences_2_words = [w for w in sentences_2[i] if w in self.model.wv.index_to_key]\n",
    "                    sim = self.model.wv.n_similarity(sentences_1_words, sentences_2_words)\n",
    "                    sentences_sim[i] = sim\n",
    "                \n",
    "                return sentences_sim\n",
    "            else:\n",
    "                return None\n",
    "    \n",
    "    \n",
    "    def get_optimal_threshold(self, sentences_1: pd.Series, sentences_2: pd.Series, df, step=0.02):\n",
    "        if sentences_1.size != sentences_2.size or self.model is None:\n",
    "            return None\n",
    "        else:\n",
    "            threshold = 0\n",
    "            max_ = 0\n",
    "            h = step\n",
    "            steps = np.linspace(0, 1, num=int(1/h))\n",
    "            steps = np.round(steps, 2)\n",
    "            for i in steps:\n",
    "                sim =  self.predict_sentences_similarity( sentences_1, sentences_2)\n",
    "                threshold = calc_f1_score(sim, df, h)\n",
    "                print(h, threshold)\n",
    "                if threshold > max_:\n",
    "                    max_ = threshold\n",
    "                h += step\n",
    "            return max_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6008fc2",
   "metadata": {},
   "source": [
    "## Обучим word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "881c0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = read_json('./preprocessed_documents.json')\n",
    "modelResearcher_w2v = ModelResearcher()\n",
    "modelResearcher_w2v.train(data_df, model=\"w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "05492e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_unmatch_df = read_json('./dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1e6011b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_f1 = pd.concat([pd.DataFrame(match_unmatch_df[0:17]), pd.DataFrame(match_unmatch_df[30:])], axis=0)\n",
    "df_test_f1 = pd.DataFrame(match_unmatch_df[17:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0ea55edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: 33 of 46\n",
      "df_test: 13 of 46\n"
     ]
    }
   ],
   "source": [
    "print('df_train: {} of {}'.format(df_train_f1['id_rp'].size, match_unmatch_df ['id_rp'].size))\n",
    "print('df_test: {} of {}'.format(df_test_f1['id_rp'].size,match_unmatch_df['id_rp'].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1af4fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_f1 = modelResearcher_w2v.preprocess_and_save_pairs(df_train_f1, None, 'text_rp', 'text_proj')\n",
    "df_test_f1 = modelResearcher_w2v.preprocess_and_save_pairs(df_test_f1, None, 'text_rp', 'text_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "04f2d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_w2v_train = modelResearcher_w2v.predict_sentences_similarity(df_train_f1['preprocessed_text_rp'], df_train_f1['preprocessed_text_proj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8d5d904a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 0.68\n",
      "0.04 0.68\n",
      "0.06 0.68\n",
      "0.08 0.68\n",
      "0.1 0.68\n",
      "0.12000000000000001 0.68\n",
      "0.14 0.68\n",
      "0.16 0.68\n",
      "0.18 0.68\n",
      "0.19999999999999998 0.68\n",
      "0.21999999999999997 0.68\n",
      "0.23999999999999996 0.68\n",
      "0.25999999999999995 0.68\n",
      "0.27999999999999997 0.68\n",
      "0.3 0.68\n",
      "0.32 0.68\n",
      "0.34 0.68\n",
      "0.36000000000000004 0.68\n",
      "0.38000000000000006 0.68\n",
      "0.4000000000000001 0.68\n",
      "0.4200000000000001 0.694\n",
      "0.4400000000000001 0.694\n",
      "0.46000000000000013 0.694\n",
      "0.48000000000000015 0.694\n",
      "0.5000000000000001 0.694\n",
      "0.5200000000000001 0.694\n",
      "0.5400000000000001 0.694\n",
      "0.5600000000000002 0.694\n",
      "0.5800000000000002 0.723\n",
      "0.6000000000000002 0.723\n",
      "0.6200000000000002 0.667\n",
      "0.6400000000000002 0.682\n",
      "0.6600000000000003 0.682\n",
      "0.6800000000000003 0.7\n",
      "0.7000000000000003 0.718\n",
      "0.7200000000000003 0.743\n",
      "0.7400000000000003 0.743\n",
      "0.7600000000000003 0.75\n",
      "0.7800000000000004 0.714\n",
      "0.8000000000000004 0.615\n",
      "0.8200000000000004 0.435\n",
      "0.8400000000000004 0.364\n",
      "0.8600000000000004 0.364\n",
      "0.8800000000000004 0.3\n",
      "0.9000000000000005 0.211\n",
      "0.9200000000000005 0.0\n",
      "0.9400000000000005 0.0\n",
      "0.9600000000000005 0.0\n",
      "0.9800000000000005 0.0\n",
      "1.0000000000000004 0.0\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "result_w2v_train_opt = modelResearcher_w2v.get_optimal_threshold(df_train_f1['preprocessed_text_rp'], df_train_f1['preprocessed_text_proj'], df_train_f1, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3acd5ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(result_w2v_train_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7b912df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score train w2v: 0.75\n"
     ]
    }
   ],
   "source": [
    "f1_w2v_train = calc_f1_score(result_w2v_train, df_train_f1, result_w2v_train_opt)\n",
    "print('F1-score train w2v: {}'.format(f1_w2v_train ))\n",
    "df_train_f1.drop('score', inplace=True, axis=1, errors='ignore')\n",
    "df_train_f1.insert(loc=4, column='score', value=result_w2v) \n",
    "# df_train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1f38d8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score test w2v: 0.833\n"
     ]
    }
   ],
   "source": [
    "result_w2v_test = modelResearcher_w2v.predict_sentences_similarity(df_test_f1['preprocessed_text_rp'], df_test_f1['preprocessed_text_proj'])\n",
    "f1_w2v_test = calc_f1_score(result_w2v_test, df_test_f1, result_w2v_train_opt)\n",
    "print('F1-score test w2v: {}'.format(f1_w2v_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f16aec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_f1.drop('score', inplace=True, axis=1, errors='ignore')\n",
    "df_test_f1.insert(loc=4, column='score', value=result_w2v_test) \n",
    "# df_test_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c5d74b",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c8c12c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast_text\n"
     ]
    }
   ],
   "source": [
    "modelResearcher_ft = ModelResearcher()\n",
    "data_df = read_json('./preprocessed_documents.json')\n",
    "modelResearcher_ft.train(data_df, model=\"fast_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "88ac642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# f1_ft_train = calc_f1_score(result_ft_train, df_train_f1, 0.78)\n",
    "# print('F1-score train ft: {}'.format(f1_ft_train ))\n",
    "\n",
    "# result_ft_test = modelResearcher_ft.predict_sentences_similarity(df_test_f1['preprocessed_text_rp'], df_test_f1['preprocessed_text_proj'])\n",
    "# f1_ft_test = calc_f1_score(result_ft_test, df_test_f1, 0.78)\n",
    "# print('F1-score test ft: {}'.format(f1_ft_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "57138a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 0.68\n",
      "0.04 0.68\n",
      "0.06 0.68\n",
      "0.08 0.68\n",
      "0.1 0.68\n",
      "0.12000000000000001 0.68\n",
      "0.14 0.68\n",
      "0.16 0.68\n",
      "0.18 0.68\n",
      "0.19999999999999998 0.68\n",
      "0.21999999999999997 0.68\n",
      "0.23999999999999996 0.68\n",
      "0.25999999999999995 0.68\n",
      "0.27999999999999997 0.68\n",
      "0.3 0.68\n",
      "0.32 0.68\n",
      "0.34 0.68\n",
      "0.36000000000000004 0.68\n",
      "0.38000000000000006 0.68\n",
      "0.4000000000000001 0.68\n",
      "0.4200000000000001 0.68\n",
      "0.4400000000000001 0.68\n",
      "0.46000000000000013 0.68\n",
      "0.48000000000000015 0.68\n",
      "0.5000000000000001 0.68\n",
      "0.5200000000000001 0.68\n",
      "0.5400000000000001 0.68\n",
      "0.5600000000000002 0.68\n",
      "0.5800000000000002 0.68\n",
      "0.6000000000000002 0.68\n",
      "0.6200000000000002 0.68\n",
      "0.6400000000000002 0.68\n",
      "0.6600000000000003 0.68\n",
      "0.6800000000000003 0.681\n",
      "0.7000000000000003 0.696\n",
      "0.7200000000000003 0.696\n",
      "0.7400000000000003 0.682\n",
      "0.7600000000000003 0.682\n",
      "0.7800000000000004 0.667\n",
      "0.8000000000000004 0.737\n",
      "0.8200000000000004 0.8\n",
      "0.8400000000000004 0.788\n",
      "0.8600000000000004 0.615\n",
      "0.8800000000000004 0.435\n",
      "0.9000000000000005 0.286\n",
      "0.9200000000000005 0.3\n",
      "0.9400000000000005 0.111\n",
      "0.9600000000000005 0.0\n",
      "0.9800000000000005 0.0\n",
      "1.0000000000000004 0.0\n"
     ]
    }
   ],
   "source": [
    "result_ft_train_opt = modelResearcher_ft.get_optimal_threshold(df_train_f1['preprocessed_text_rp'], df_train_f1['preprocessed_text_proj'], df_train_f1, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d873b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "print(result_ft_train_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "07d8f409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score train ft: 0.737\n"
     ]
    }
   ],
   "source": [
    "result_ft_train = modelResearcher_ft.predict_sentences_similarity(df_train_f1['preprocessed_text_rp'], df_train_f1['preprocessed_text_proj'])\n",
    "f1_ft_train = calc_f1_score(result_ft_train, df_train_f1, result_ft_train_opt)\n",
    "print('F1-score train ft: {}'.format(f1_ft_train ))\n",
    "df_train_f1.drop('score', inplace=True, axis=1, errors='ignore')\n",
    "df_train_f1.insert(loc=4, column='score', value=result_ft_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "218f1a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score test ft: 0.833\n"
     ]
    }
   ],
   "source": [
    "result_ft_test = modelResearcher_ft.predict_sentences_similarity(df_test_f1['preprocessed_text_rp'], df_test_f1['preprocessed_text_proj'])\n",
    "f1_ft_test = calc_f1_score(result_ft_test, df_test_f1, result_ft_train_opt)\n",
    "print('F1-score test ft: {}'.format(f1_ft_test))\n",
    "df_test_f1.drop('score', inplace=True, axis=1, errors='ignore')\n",
    "df_test_f1.insert(loc=4, column='score', value=result_ft_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2ec43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
